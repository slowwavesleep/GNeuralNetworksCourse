{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nn5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhKhkvlQUL_c",
        "colab_type": "text"
      },
      "source": [
        "1. Проверить как идет обучение при различных параметрах модели для выборки \"Ирисы Фишера\":\n",
        "    \n",
        "    - Измените размер batch_size : 1, 10, 20, 50\n",
        "    \n",
        "    - измените значение lyambd: 0.01, 0.1, 0.5, 1 \n",
        "    \n",
        "    - измените число нейронов в скрытом слое : 1, 5, 50\n",
        "\n",
        "2. Сделайте несколько перезапусков каждой модели (10 перезапусков с вычислением среднего и дисперсии для оценки точности).\n",
        "\n",
        "3. Оцените изменения параметров статистик точности при изменении параметров модели. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv22alScUH2o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXIcb5DwVEDC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_one_hot(Y):\n",
        "    n_col = np.amax(Y) + 1\n",
        "    binarized = np.zeros((len(Y), n_col))\n",
        "    for i in range(len(Y)):\n",
        "        binarized[i, Y[i]] = 1.\n",
        "    return binarized\n",
        "\n",
        "def from_one_hot(Y):\n",
        "    arr = np.zeros((len(Y), 1))\n",
        "\n",
        "    for i in range(len(Y)):\n",
        "        l = layer2[i]\n",
        "        for j in range(len(l)):\n",
        "            if(l[j] == 1):\n",
        "                arr[i] = j+1\n",
        "    return arr\n",
        "\n",
        "\n",
        "def sum_neuron(x=None, w=None):\n",
        "    return np.dot(w.T,x.T )\n",
        "\n",
        "def sigmoid_complex_neuron(x=None, w=None, bias=0, lambda_=1):\n",
        "    s = sum_neuron(x=x, w=w).T\n",
        "    y = 1 / (1 + np.exp(-s / lambda_))\n",
        "    return y\n",
        "\n",
        "def sigmoid_deriv(g):\n",
        "    return g * (1 - g)\n",
        "\n",
        "def normalize(X, axis=-1, order=2):\n",
        "    l2 = np.atleast_1d(np.linalg.norm(X, order, axis))\n",
        "    l2[l2 == 0] = 1\n",
        "    return X / np.expand_dims(l2, axis)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kSDDeMN0UOnG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def custom_net(X_train, X_test, y_train, y_test, epochs=5000, neurons=5, lambda_=0.1,  batch_size=10, n=0.01):\n",
        "\n",
        "    w0 = 2*np.random.random((4, neurons)) - 1\n",
        "    w1 = 2*np.random.random((neurons, 3)) - 1\n",
        "\n",
        "    errors = []\n",
        "    errors_test = []\n",
        "\n",
        "    \n",
        "    \n",
        "    layer0 = X_train\n",
        "    layer1 = sigmoid_complex_neuron(x=layer0, w=w0)\n",
        "    layer2 = sigmoid_complex_neuron(x=layer1, w=w1)\n",
        "    layer2_error = (y_train - layer2)\n",
        "\n",
        " \n",
        "    Q = np.mean(np.abs(layer2_error)).copy()\n",
        "    \n",
        "    for i in range(epochs):\n",
        "\n",
        "        j = np.random.randint(0, X_train.shape[0], (batch_size))\n",
        "        layer0 = X_train[j,:]\n",
        "        layer1 = sigmoid_complex_neuron(x=layer0, w=w0)\n",
        "        layer2 = sigmoid_complex_neuron(x=layer1, w=w1)\n",
        "\n",
        "        layer2_error = y_train[j] - layer2\n",
        "\n",
        "        \n",
        "        \n",
        "        Q = Q * (1 - lambda_) + lambda_ * np.mean(np.abs(layer2_error))\n",
        "        errors.append(Q.copy())\n",
        "\n",
        "        dlayer2 = sigmoid_deriv(layer2)\n",
        "        dlayer1 = sigmoid_deriv(layer1)\n",
        " \n",
        "        layer2_delta = layer2_error*dlayer2 \n",
        "    \n",
        "    \n",
        "        layer1_error = np.dot(layer2_delta, w1.T)\n",
        "                \n",
        "        layer1_delta = layer1_error * dlayer1 \n",
        "                 \n",
        "        dw1 = np.dot(layer2_delta.reshape((layer2_delta.shape[1], layer2_delta.shape[0])), layer1) * n\n",
        "        dw0 = np.dot(layer1_delta.reshape((neurons, layer1_delta.shape[0])), layer0) * n\n",
        "       \n",
        "        w1 += dw1.T\n",
        "        w0 += dw0.T\n",
        "        \n",
        "        error = np.mean(np.abs(layer2_error))\n",
        "        accuracy = (1 - error.copy()) * 100\n",
        "\n",
        "        layer0_test = X_test\n",
        "        layer1_test = sigmoid_complex_neuron(x=layer0_test, w=w0)\n",
        "        layer2_test = sigmoid_complex_neuron(x=layer1_test, w=w1)\n",
        "        \n",
        "        \n",
        "        layer2_error_test = y_test - layer2_test\n",
        "    \n",
        "        error = np.mean(np.abs(layer2_error_test))\n",
        "        errors_test.append(error.copy())\n",
        "    \n",
        "        accuracy_test = (1 - error.copy()) * 100\n",
        "        \n",
        "    return accuracy, accuracy_test, w0, w1, errors_test, errors\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBDr9ZWBXopa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "bea143b8-5af3-46d3-a401-a46f23606ef9"
      },
      "source": [
        "iris_ = load_iris()\n",
        "iris_data = iris_.data\n",
        "iris_target = iris_.target\n",
        "columns = iris_.feature_names\n",
        "df = pd.DataFrame(data=iris_data, columns=columns)\n",
        "df['target'] = iris_.target\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  ...  petal width (cm)  target\n",
              "0                5.1               3.5  ...               0.2       0\n",
              "1                4.9               3.0  ...               0.2       0\n",
              "2                4.7               3.2  ...               0.2       0\n",
              "3                4.6               3.1  ...               0.2       0\n",
              "4                5.0               3.6  ...               0.2       0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eks_YNJKWd4-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "73a46e4c-61b4-4ed7-ed97-e245afe5e266"
      },
      "source": [
        "X = normalize(df[columns].values)\n",
        "y = df['target'].values\n",
        "\n",
        "y = y.flatten()\n",
        "y = to_one_hot(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
        "\n",
        "print(X_train.shape)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(100, 4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maN61Zs9ZG4S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_sizes = [1, 10, 20, 50]\n",
        "lambdas = [0.01, 0.1, 0.5, 1]\n",
        "n_neurons = [1, 5, 50]\n",
        "n_models = 10"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4GoAYK4bwYl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "acedeae2-96bf-4b71-a17e-37d361fb7887"
      },
      "source": [
        "results = {}\n",
        "for size in batch_sizes:\n",
        "  result = []\n",
        "  for i in range(n_models):\n",
        "    accuracy = custom_net(X_train, X_test, y_train, y_test, batch_size=size)[1]\n",
        "    result.append(accuracy)\n",
        "  results[size] = {'mean': np.mean(result), 'variance': np.var(result, ddof=1)}\n",
        "\n",
        "results"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: {'mean': 55.3799202370801, 'variance': 0.15752141613178056},\n",
              " 10: {'mean': 55.503998140194525, 'variance': 0.12091488778198108},\n",
              " 20: {'mean': 55.32386941526954, 'variance': 0.12858001777167855},\n",
              " 50: {'mean': 55.440482678044624, 'variance': 0.07654968420449268}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiB6V4cDfWEL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "54e7d604-16e5-4dc7-b759-f89482bc4b26"
      },
      "source": [
        "results = {}\n",
        "for l in lambdas:\n",
        "  result = []\n",
        "  for i in range(n_models):\n",
        "    accuracy = custom_net(X_train, X_test, y_train, y_test, lambda_=l)[1]\n",
        "    result.append(accuracy)\n",
        "  results[l] = {'mean': np.mean(result), 'variance': np.var(result, ddof=1)}\n",
        "\n",
        "results"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0.01: {'mean': 55.321146755131664, 'variance': 0.05454993940983452},\n",
              " 0.1: {'mean': 55.48199494289427, 'variance': 0.19241513038765326},\n",
              " 0.5: {'mean': 55.42472397719814, 'variance': 0.06414892866753659},\n",
              " 1: {'mean': 55.42156788286017, 'variance': 0.10308838762381656}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__Mlb77gf4LY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "5c6fd015-b403-468d-b2d5-a91e5d356ae2"
      },
      "source": [
        "results = {}\n",
        "for n in n_neurons:\n",
        "  result = []\n",
        "  for i in range(n_models):\n",
        "    accuracy = custom_net(X_train, X_test, y_train, y_test, neurons=n)[1]\n",
        "    result.append(accuracy)\n",
        "  results[n] = {'mean': np.mean(result), 'variance': np.var(result, ddof=1)}\n",
        "\n",
        "results"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{1: {'mean': 55.381600152164154, 'variance': 0.10769437505098248},\n",
              " 5: {'mean': 55.23952513321363, 'variance': 0.07010429928462668},\n",
              " 50: {'mean': 56.57086149001515, 'variance': 1.325467481793543}}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IopJPIQBiEt4",
        "colab_type": "text"
      },
      "source": [
        "По результатам видим, что от параметра `batch_size` точность практически не зависит. В случае с параметром `lambda_` точность связана больше, т.к. дисперсия меньше, а значит разница в меньшей степени объясняется случайным распределением. Количество нейронов дает прирост в точности, но при этом при большом количестве нейронов увеличивается разброс в результатах, что, кажется, ожидаемо."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DJ16XyIojBFt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}